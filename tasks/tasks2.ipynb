{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e2274a",
   "metadata": {},
   "source": [
    "# Task for session2_cont and session3: \n",
    "## Edge-Preserving Denoising Filters & Feature Matching\n",
    "\n",
    "**Instructions:**  \n",
    "**please dont use .py to solve this task, just use tasks2.ipynb and edit the cells.**\n",
    "- After forking the [SkyXperts-Vision-Course repo](https://github.com/ffathy-tdx/SkyXperts-Vision-Course) on GitHub. (you should have already dont this in the last session & uploaded task1)\n",
    "- Go to your fork of the repo on GitHub.\n",
    "- At the top, look for a yellow box that says “This branch is X commits behind…”\n",
    "- Click the Sync fork or Update branch button.\n",
    "The new task will show up in your tasks/ folder.  \n",
    "- Upload your task to your forked repo (like you've done with task1 before)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58e9e5",
   "metadata": {},
   "source": [
    "## 1. DoG, LoG, and Edge-Preserving Denoising Filters\n",
    "\n",
    "**Task:**\n",
    "- Briefly read the descriptions below, then apply each filter to `'sample.jpg'` (or any test image you choose).\n",
    "- Compare the results visually and write your observations.\n",
    "\n",
    "**Background:**\n",
    "- **DoG (Difference of Gaussian):** Used for edge detection by subtracting two blurred versions of the image (with different Gaussian sigmas).\n",
    "- **LoG (Laplacian of Gaussian):** Uses a single Gaussian blur followed by Laplacian to highlight regions of rapid intensity change (edges).\n",
    "- **Edge-Preserving Denoising (Bilateral Filter):** Smooths image while preserving edges (unlike simple Gaussian blur). You've already used this at the end of task1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c88459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('sample.jpg', 0)  # Use grayscale for filtering\n",
    "plt.imshow(img, cmap='gray'); plt.axis('off'); plt.title('Original Image'); plt.show()\n",
    "\n",
    "# TODO: Apply DoG\n",
    "# TODO: Apply LoG\n",
    "# TODO: Apply bilateral (edge-preserving) filter\n",
    "# Show all results for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b653404",
   "metadata": {},
   "source": [
    "**Q1: What differences do you observe between DoG, LoG, and the edge-preserving filter?**\n",
    "\n",
    "_Write your observations here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec143be",
   "metadata": {},
   "source": [
    "## 2. Keypoints & Descriptors: SIFT vs. ORB\n",
    "\n",
    "**Task:**\n",
    "- Detect and plot keypoints on `'sample.jpg'` using SIFT and ORB.\n",
    "- Compare the number and distribution of detected keypoints.\n",
    "\n",
    "**Background:**\n",
    "- **Keypoints:** Distinctive image points (corners/blobs) useful for matching.\n",
    "- **Descriptors:** Vectors that describe local patches around keypoints for comparison/matching.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect and plot SIFT keypoints\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect and plot ORB keypoints\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# TODO: Count and compare number of keypoints for SIFT and ORB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de463ee",
   "metadata": {},
   "source": [
    "**Q2: How do the number and distribution of keypoints differ between SIFT and ORB?**\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b06ae",
   "metadata": {},
   "source": [
    "## 3. Feature Matching with Descriptors\n",
    "\n",
    "**Task:**\n",
    "- Load a second image (e.g., `'sample2.jpg'`).\n",
    "- Detect keypoints/descriptors using SIFT or ORB in both images.\n",
    "- Match the features between the images using BFMatcher or FLANN.\n",
    "- Plot the top matches.\n",
    "\n",
    "**Background:**\n",
    "- **Feature matching** helps recognize objects/scenes or estimate image transformations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046817e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second image\n",
    "img2 = cv2.imread('sample2.jpg', 0)\n",
    "\n",
    "# Detect SIFT keypoints/descriptors in both images\n",
    "\n",
    "\n",
    "# BFMatcher with default params\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# Draw matches\n",
    "\n",
    "# bonus TODO: Try with ORB or FLANN if you like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9cbd0b",
   "metadata": {},
   "source": [
    "**Q3: What do you notice about the feature matches? Are there any mismatches or errors? How might you improve the matching process?**\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0709b3",
   "metadata": {},
   "source": [
    "**Bonus Task (Optional, for extra credit):**\n",
    "- Try using different image preprocessing steps *before* edge detection or feature extraction.\n",
    "    - For example:\n",
    "        - Add noise to your image (e.g., Gaussian noise, salt-and-pepper noise).\n",
    "        - Apply a sharpening filter to your image.\n",
    "    - Then, run DoG, LoG, or any edge-preserving filter and observe the changes.\n",
    "- **What to do:**\n",
    "    - Show the results (images/plots) for at least one type of preprocessing + edge detection.\n",
    "    - Briefly explain:\n",
    "        - How does noise affect edge maps or keypoints?\n",
    "        - Does sharpening make features easier or harder to detect/match?\n",
    "\n",
    "**You can add your code and observations in the cells below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f17a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf113b2",
   "metadata": {},
   "source": [
    "_What are your observations?_\n",
    "write them here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90a09a",
   "metadata": {},
   "source": [
    "## 4. Reflection (Optional)\n",
    "\n",
    "- What was the most challenging or interesting part of this task for you?\n",
    "- Any feedback or thoughts?\n",
    "\n",
    "_Write your reflection here._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
